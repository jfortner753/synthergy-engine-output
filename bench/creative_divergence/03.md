Here’s a fresh method you can pilot right away in a remote org:

# Φ-Field Coherence Drift Radar (Φ-CDR)

**Idea in one line:** model the team’s “shared frame” as a living vector+graph, watch how language, goals, and decisions phase-shift over time, and trigger small resets before drift compounds.

## 0) What counts as “coherence drift”?

A measurable gap between (a) the team’s stated mission/sprint goal and (b) what people *actually* talk about, do, and decide—observable as semantic divergence, decision graph mismatch, and adoption lag.

---

## 1) Canonical Frame Encoding (once per sprint)

Create a compact “north star” you can measure against:

* **Goal Vector `gₜ`**: a single 768-d embedding (any sentence-embedding model) of your sprint objective (≤30 words).
* **Lexicon `Λₜ`**: 15–30 canonical terms/phrases that express scope, interfaces, and success metrics.
* **Decision DAG `Dₜ`**: a small graph of current decisions → owners → affected artifacts.

This is the “standing wave” you’re trying to keep stable; if it degrades, you microstep instead of committing big changes.

---

## 2) Passive Drift Sensors (daily)

Instrument *only* metadata and public team spaces (privacy-first):

1. **Language Alignment**

   * **Goal Fit**: cosine(v(updateᵢ), `gₜ`) for each person’s weekly note/PRD header.
   * **Lexicon Stability**: Jensen–Shannon divergence between team vocab vs. `Λₜ`.
   * **Term Diffusion Lag**: standard deviation of first-use timestamps for new terms across roles.

2. **Decision Topology**

   * **Graph Edit Distance** between `Dₜ` (planned) and `Ďₜ` (observed via PRs/tickets/meeting notes).
   * **Reopen Rate**: fraction of “closed” decisions reopened within 14 days.
   * **Branch Factor Drift**: change in out-degree at key decision nodes (proxy for scope creep).

3. **Rhythm & Intent**

   * **Intent Spread**: variance of Goal Fit across people (fragmentation signal).
   * **Latency & Bounce**: time-to-decision and cross-handoff count per issue (coordination drag).

Each sensor outputs a z-score; collect them as feature vector **zₜ**.

---

## 3) Fuse to a Single Index (explainable)

Compute the **Standing-Wave Coherence Index (SWCI)** on a 0–100 scale:

```
driftₜ = σ( wᵀ zₜ )                 # σ = logistic, w weights by importance
SWCIₜ = 100 · (1 − driftₜ)          # higher is better
```

* Use an exponentially-weighted moving average (EWMA, α≈0.3) for stability.
* Keep **feature attributions** (e.g., SHAP) so alerts always show “why.”

**Thresholds** (defaults that work for most sprints):

* **Warn** if SWCIₜ < 72 for 2 consecutive days.
* **Degrade ☽** if SWCIₜ < 60 or any single sensor > +2.5σ. On ☽, only microstep until clarity is restored.

---

## 4) Triggered Micro-Rituals (15 minutes, async-friendly)

When **Warn** or **☽** trips:

1. **Mirror Sync (10-10-10)**

   * 10 words: “Our sprint is to ___.” (each person, one line)
   * 10 minutes: cluster the lines; compute centroid; show misfits.
   * 10 minutes: rewrite the single-sentence goal and update `Λₜ`.

2. **Decision Sweep**

   * List the top 3 drift contributors from SWCI explanation.
   * Close/reaffirm/re-route the corresponding nodes in `Dₜ`.

3. **Re-embed**

   * Recompute `gₜ`, refresh `Λₜ`, and rebuild baselines immediately.

This matches a “pause/microstep/commit” move policy and demands receipts of the decision state.

---

## 5) Minimal Implementation Sketch (no new vendor needed)

* **Ingest**: Git/PR titles, issue titles, one weekly note per person, decision log doc.
* **Embed**: run a local sentence-embedding model; store vectors for goal, updates.
* **Graphs**: maintain `Dₜ` in a YAML/JSON file; auto-diff with observed dependencies.
* **Index**: compute z-scores, EWMA, SWCI daily; post a tiny dashboard and a single-line status:
  `SWCI 68 ☽ — main drivers: lexicon drift (+1.9σ), reopen rate (+1.6σ).`
* **Receipts**: every alert posts a short receipt (why/what changed), staying consistent with your commit policy and “include memory_mass, Φ_sync, move decision” telemetry.

---

## 6) Metrics to Watch

* **Alignment Spread**: top-to-bottom quartile gap in Goal Fit.
* **Time to Re-convergence**: days from ☽ to SWCI ≥ 80.
* **Reopen Half-Life**: median time for reopened decisions to settle.
* **Sync Alignment (Φ_sync)** on “commit” decisions—use it as a health overlay on SWCI.

---

## 7) Guardrails & Ethics

* Default **opt-in**, redact names in dashboards; show *team* distributions, not individuals.
* Focus on **public artifacts** (no DMs).
* Make every alert **actionable**: includes top 3 features and the smallest next move (microstep vs. commit).

---

## Why this works

Coherence is a **field property**, not a vibe. By encoding a small, explicit “standing wave” (goal/lexicon/decisions) and measuring **phase lag** between planned and observed signals, drift becomes visible early—before it shows up as missed deadlines or brittle handoffs. The method cleanly plugs into a pause/microstep/commit loop and emits receipts as part of normal operating rhythm.

---

## Quick start (2-week pilot)

1. Pick one team/sprint. Author the initial `gₜ`, `Λₜ`, `Dₜ`.
2. Run the sensors daily; post SWCI + top drivers in the team channel.
3. Run the **Mirror Sync** the first time SWCI < 72.
4. At retro: keep any sensor that proved predictive; adjust weights `w`.

---

### Receipts (Φ Synthergy Engine)

* **question**: Invent a new method for detecting coherence drift in distributed teams.
* **premises**: Distributed comms create semantic + decision lag; small early corrections are cheaper than late course-changes.
* **steps**: encode canonical frame → collect drift sensors → fuse to SWCI → trigger micro-rituals → re-embed → track metrics.
* **sources**: coupling to standing-wave/microstep/receipts and memory-mass/Φ_sync telemetry from engine spec.
* **uncertainties**: best universal thresholds; embedding choice across domains; privacy acceptance in different org cultures.
* **ΔΦ**: predicted coherence gain from introducing SWCI + Mirror Sync is positive, especially in high-churn sprints.
* **move_decision**: **commit** (method is self-contained and actionable).
* **ethics_ok**: yes (privacy-first, opt-in, aggregate).
* **energy_cost**: low (daily batch embedding + simple graphs).
* **memory.mass**: m_mem not externally readable → treat as **level: medium** for default ops (fail-safe bias).
* **creative mode**: on.

  * **lane**: macro (system-synthesis)
  * **archetype**: coherence radar
  * **Φ_sync**: ≥ 0.60 with your operating loop (fits pause/microstep/commit, receipts)
  * **repayment**: ≤ 5 cycles (keep only the sensors that prove predictive).
  * **originality/effectiveness**: high novelty; effectiveness improves with explainable alerts and micro-rituals.
